{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Final Model.ipynb","provenance":[{"file_id":"1UQUnqyHrzSZJr9H0Vi2mWUh-iQhbgTtv","timestamp":1617123690298}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.6"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K7DxFXyRUNPl","executionInfo":{"status":"ok","timestamp":1617969770785,"user_tz":-60,"elapsed":1596,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}},"outputId":"b1a9caa9-5bab-4f48-c8c4-9ce00d20aab1"},"source":["# For Google Colab use\n","try:\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount=True)\n","    %cd '/content/drive/MyDrive/Colab Notebooks/MInf-DeepfakeDetection-FrameDifferencing'    \n","except ModuleNotFoundError:\n","    pass"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Colab Notebooks/MInf-DeepfakeDetection-FrameDifferencing\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7W8i8xxtURw5","executionInfo":{"status":"ok","timestamp":1617969773944,"user_tz":-60,"elapsed":4741,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}}},"source":["# Imports\n","from __future__ import division\n","\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n","from numpy.random import seed\n","from time import time\n","from pathlib import Path\n","\n","import tensorflow as tf\n","\n","import keras\n","from keras import preprocessing\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras import layers, Model\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","from keras.optimizers import *\n","from keras.applications import *\n","from keras import metrics\n","from keras.losses import binary_crossentropy\n","from keras import backend as K\n","\n","try:\n","    import face_recognition\n","except ModuleNotFoundError:\n","    !pip install face_recognition\n","\n","from Util import pipeline\n","from Baseline.classifiers import *\n","# from Util import experiment_tuner_models"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"pRRdjGi-Yltx","executionInfo":{"status":"ok","timestamp":1617969774284,"user_tz":-60,"elapsed":5071,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}}},"source":["def evaluate_model(TEST_MODEL, EXPERIMENT_NAME:str, TEST_DIR:str, BACTH_SIZE:int=64, \\\n","                   IMG_HEIGHT:int=256, IMG_WIDTH:int=256, DATA_GENERATOR_SEED:int=1337, \\\n","                   HISTORY=None):\n","    \n","    from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n","    \n","    EXPERIMENT_NAME = EXPERIMENT_NAME.replace(\" \", \"_\")\n","    EXPERIMENT_FOLDER_NAME = f'./Results/{EXPERIMENT_NAME}'\n","    Path(EXPERIMENT_FOLDER_NAME).mkdir(parents=True, exist_ok=True)\n","\n","    # Define testing datagen\n","    print('Defining testing datagen...')\n","    TEST_DATAGEN = ImageDataGenerator(rescale=1./255)\n","    TEST_GENERATOR = TEST_DATAGEN.flow_from_directory(directory = TEST_DIR,\n","                                                      batch_size = BACTH_SIZE,\n","                                                      class_mode = 'binary', \n","                                                      target_size =  (IMG_HEIGHT, IMG_WIDTH),                                \n","                                                      seed = DATA_GENERATOR_SEED,\n","                                                      follow_links = True)\n","\n","    # Evaluate test set and get metrics, e.g. loss\n","    print('Evaluating test set and getting metrics...')\n","    TEST_HISORY = TEST_MODEL.evaluate(TEST_GENERATOR,\n","                                      batch_size = BACTH_SIZE,\n","                                      return_dict = True)\n","    TEST_GENERATOR.reset()\n","\n","    # Get predictions and ground truths\n","    print('Predicting on test set...')\n","    Y_pred = (TEST_MODEL.predict(TEST_GENERATOR)).ravel()\n","    Y_true = (TEST_GENERATOR.classes).ravel()\n","\n","    # Plot AUC and save plot\n","    print('Plotting AUC...')\n","    fpr, tpr, _ = roc_curve(Y_true, Y_pred)\n","    try:\n","        roc_auc = auc(fpr, tpr)\n","    except:\n","        roc_auc = None\n","        roc_auc = auc(fpr, tpr)\n","\n","    plt.figure()\n","    plt.plot(fpr, tpr, color='magenta', lw=2, label='ROC curve (area = %0.3f)' % roc_auc)\n","    plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.01])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title(f'{EXPERIMENT_NAME.replace(\"_\", \" \")} ROC')\n","    plt.legend(loc=\"lower right\")\n","    print(f'Saving AUC to {EXPERIMENT_FOLDER_NAME}/{EXPERIMENT_NAME}_AUC.pdf')\n","    plt.savefig(f'{EXPERIMENT_FOLDER_NAME}/{EXPERIMENT_NAME}_AUC.pdf')\n","\n","    # Create file, write metrics\n","    print(f'Saving summary file to {EXPERIMENT_FOLDER_NAME}/{EXPERIMENT_NAME}_summary.txt')\n","    summary_file = open(f'{EXPERIMENT_FOLDER_NAME}/{EXPERIMENT_NAME}_summary.txt', 'w')\n","    summary_file.write(str(TEST_HISORY).replace(', \\'', ':\\n\\n'))\n","    print(str(TEST_HISORY).replace(', \\'', ':\\n'))\n","\n","    # find classification thershold which results in max auc\n","    roc_aucs = []\n","    for thrshld in map(lambda x: x/1000.0, range(0, 1000+1)):\n","        fpr, tpr, _ = roc_curve(Y_true, (Y_pred >= thrshld).astype(int))\n","        roc_aucs.append((auc(fpr, tpr), thrshld))\n","    max_auc_thrshld = max(roc_aucs)[1]\n","\n","    # use max auc classification thershold to get confusion matrix and classification report\n","    y_pred = (Y_pred >= max_auc_thrshld).astype(int)\n","    summary_output_text = f'''\\n\\nTHRESHOLD = {max_auc_thrshld}\n","    \\nCONFUSION MATRIX\\n{confusion_matrix(Y_true, y_pred)}\n","    \\nCLASSIFICATION REPORT\\n{classification_report(Y_true, y_pred, target_names = [\"REAL\", \"FAKE\"])}\n","    _____________________________________________________\\n'''\n","    summary_file.write(summary_output_text)\n","    summary_file.write(f'''\\n{list(zip(Y_true, Y_pred))}''')\n","    print(summary_output_text)\n","    summary_file.close()\n","\n","    # plot history (of training), if provided\n","    if HISTORY is not None:\n","        print('Plotting training history x4 plots...')\n","        acc = HISTORY.history['acc']\n","        auc = HISTORY.history['auc']\n","        loss = HISTORY.history['loss']\n","        fp = HISTORY.history['fp']\n","\n","        val_acc = HISTORY.history['val_acc']\n","        val_auc = HISTORY.history['val_auc']\n","        val_loss = HISTORY.history['val_loss']\n","        val_fp = HISTORY.history['val_fp']\n","\n","        epochs = range(len(acc))\n","        fig, axs = plt.subplots(2, 2, figsize=(10,10))\n","        fig.suptitle(f'{EXPERIMENT_NAME.replace(\"_\", \" \")} Train & Validation Metrics')\n","\n","        axs[0, 0].plot(epochs, acc, 'r', label='Train Binary Accuracy')\n","        axs[0, 0].plot(epochs, val_acc, 'b', label='Validation Binary Accuracy')\n","        axs[0, 0].set_title('Binary Accuracy')\n","        axs[0, 0].set_ylabel('Accuracy')\n","        axs[0, 0].set_xlabel('Epochs')\n","        axs[0, 0].legend()\n","\n","        axs[0, 1].plot(epochs, loss, 'r', label='Train Loss')\n","        axs[0, 1].plot(epochs, val_loss, 'b', label='Validation Loss')\n","        axs[0, 1].set_title('Loss')\n","        axs[0, 1].set_ylabel('Loss')\n","        axs[0, 1].set_xlabel('Epochs')\n","        axs[0, 1].legend()\n","\n","        axs[1, 0].plot(epochs, auc, 'r', label='Train AUC')\n","        axs[1, 0].plot(epochs, val_auc, 'b', label='Validation AUC')\n","        axs[1, 0].set_title('AUC')\n","        axs[1, 0].set_ylabel('AUC')\n","        axs[1, 0].set_xlabel('Epochs')\n","        axs[1, 0].legend()\n","\n","        axs[1, 1].plot(epochs, fp, 'r', label='Train False Positives')\n","        axs[1, 1].plot(epochs, val_fp, 'b', label='Validation False Positives')\n","        axs[1, 1].set_title('False Positives')\n","        axs[1, 1].set_ylabel('FP')\n","        axs[1, 1].set_xlabel('Epochs')\n","        axs[1, 1].legend()\n","        \n","        print(f'Saving history plots to {EXPERIMENT_FOLDER_NAME}/{EXPERIMENT_NAME}_history.pdf')\n","        fig.savefig(f'{EXPERIMENT_FOLDER_NAME}/{EXPERIMENT_NAME}_history.pdf')\n","    \n","    return Y_true, Y_pred"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKnpjycuYlt5","executionInfo":{"status":"ok","timestamp":1617969774286,"user_tz":-60,"elapsed":5067,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}}},"source":["# for df_name, df_type in tqdm([('Random_Frame', 'rnd'), ('Frame_Averaging', 'avg'), ('Frame_Difference', 'diff')]):\n","#         for weight_path in [f'./Baseline/weights/MesoInception_F2F.h5', f'./Baseline/weights/MesoInception_DF.h5']:\n","#             weight_name = weight_path.split('_')[-1].replace('.h5', '')\n","#             print(df_type.upper(), weight_name.upper())\n","\n","#             TEST_MODEL = None\n","#             TEST_MODEL = MesoInception4().model\n","#             TEST_MODEL.load_weights(weight_path)\n","\n","#             evaluate_model(TEST_MODEL = TEST_MODEL,\n","#                            EXPERIMENT_NAME = f'Untrained_MesoInception4_({weight_name})_on_{df_name}_Dataset',\n","#                            TEST_DIR = f'./Celeb-DF-v2/Celeb-{df_type}-30-test')"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F6iN8C_aMd6Q","outputId":"c20a7e67-d1cb-4307-92cd-30368d235916"},"source":["# General model settings\n","IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS = 256, 256, 3\n","EPOCHS = 100\n","DATA_GENERATOR_SEED = 1337\n","BATCH_SIZE = 64\n","VALIDATION_SPLIT = 0.2\n","\n","tf.random.set_seed(DATA_GENERATOR_SEED)\n","seed(DATA_GENERATOR_SEED)\n","\n","# Pick dataset; DF_TYPE={'rnd', 'avg'}\n","for df_name, DF_TYPE in tqdm([('Random_Frame', 'rnd'), ('Frame_Averaging', 'avg'), ('Frame_Difference', 'diff')][::-1]):\n","    TRAIN_VAL_DIR = f'./Celeb-DF-v2/Celeb-{DF_TYPE}-30'\n","    print(f'{DF_TYPE}!!!')\n","\n","    print('Setting up datagens...')\n","    TRAIN_DATAGEN = ImageDataGenerator(rescale = 1.0/255.0, horizontal_flip = True, fill_mode='nearest', validation_split = VALIDATION_SPLIT)\n","    TRAIN_GENERATOR = TRAIN_DATAGEN.flow_from_directory(directory = TRAIN_VAL_DIR,\n","                                                        batch_size = BATCH_SIZE,\n","                                                        class_mode = 'binary', \n","                                                        target_size = (IMG_HEIGHT, IMG_WIDTH),\n","                                                        subset = 'training',\n","                                                        seed = DATA_GENERATOR_SEED,\n","                                                        follow_links = True)\n","\n","    VAL_DATAGEN = ImageDataGenerator(rescale = 1.0/255.0, validation_split = VALIDATION_SPLIT)\n","    VALIDATION_GENERATOR = TRAIN_DATAGEN.flow_from_directory(directory = TRAIN_VAL_DIR,\n","                                                             batch_size = BATCH_SIZE,\n","                                                             class_mode = 'binary', \n","                                                             target_size = (IMG_HEIGHT, IMG_WIDTH),\n","                                                             subset = 'validation',\n","                                                             seed = DATA_GENERATOR_SEED,\n","                                                             follow_links = True)\n"," \n","    PRE_TRAINED_MODEL = Xception(input_shape = (IMG_HEIGHT,IMG_WIDTH,3),\n","                                                include_top = False,\n","                                                pooling = 'avg',\n","                                                weights = 'imagenet')\n","    for layer in PRE_TRAINED_MODEL.layers:\n","        layer.trainable = False\n","\n","    x = layers.Flatten()(PRE_TRAINED_MODEL.output)\n","    x = layers.Dense(2034, activation = 'relu')(x)\n","    x = layers.Dropout(0.3)(x)\n","    x = layers.Dense(3328, activation = 'relu')(x)\n","    x = layers.Dropout(0.2)(x)\n","    x = layers.Dense(1280, activation = 'relu')(x)\n","    x = layers.Dropout(0.15)(x)\n","    x = layers.Dense(1280, activation = 'relu')(x)\n","#     x = layers.Dropout(0)(x)\n","    x = layers.Dense(1, activation = 'sigmoid')(x)\n","    \n","    TEST_MODEL = Model(PRE_TRAINED_MODEL.input, x)\n","    \n","    TEST_MODEL.compile(optimizer = 'sgd',\n","              loss = 'binary_crossentropy',\n","              metrics = [metrics.BinaryAccuracy(name = 'acc'),\n","                         metrics.AUC(name = 'auc'),\n","                         metrics.FalsePositives(name = 'fp')])\n","\n","    train_gen_list = list(TRAIN_GENERATOR.classes)\n","    val_gen_list = list(VALIDATION_GENERATOR.classes)\n","\n","    train_neg, train_pos = train_gen_list.count(0), train_gen_list.count(1)\n","    val_neg, val_pos = val_gen_list.count(0), val_gen_list.count(1)\n","\n","    pos = train_pos + val_pos\n","    neg = train_neg + val_neg\n","    total = pos + neg\n","\n","    weight_for_0 = (1.0 / neg)*(total)/2.0 \n","    weight_for_1 = (1.0 / pos)*(total)/2.0\n","\n","    CLASS_WEIGHT = {0: weight_for_0, 1: weight_for_1}\n","    print(f'Class weights = {CLASS_WEIGHT}')\n","\n","    EARLY_STOP = EarlyStopping(monitor='val_auc',\n","                            patience=EPOCHS//10,\n","                            mode='max',\n","                            verbose=1,\n","                            restore_best_weights=True)\n","    \n","    # MODEL_CHECKPOINT = ModelCheckpoint(filepath = f'./Weights/OM-{DF_TYPE.upper()}', \n","    #                                    monitor='val_auc', \n","    #                                    verbose=0, \n","    #                                    save_best_only=True,\n","    #                                    save_weights_only=True,\n","    #                                    mode='max', \n","    #                                    save_freq='epoch')\n","    \n","    print(f'Early stopping in {EARLY_STOP.patience}')\n","\n","    HISTORY = TEST_MODEL.fit(TRAIN_GENERATOR,\n","                            steps_per_epoch = TRAIN_GENERATOR.n//TRAIN_GENERATOR.batch_size,\n","                            validation_data = VALIDATION_GENERATOR,\n","                            validation_steps = VALIDATION_GENERATOR.n//VALIDATION_GENERATOR.batch_size,\n","                            epochs = EPOCHS,\n","                            verbose = 1,\n","                            class_weight = CLASS_WEIGHT,\n","                            callbacks = [EARLY_STOP\n","                                        #  MODEL_CHECKPOINT\n","                                         ])\n","    \n","\n","#     weight_name = WEIGHTS_PATH.split('_')[-1].replace('.h5', '')\n","    evaluate_model(TEST_MODEL = TEST_MODEL,\n","                   EXPERIMENT_NAME = f'Our_Model_on_{df_name}_Dataset',\n","                   TEST_DIR = f'./Celeb-DF-v2/Celeb-{DF_TYPE}-30-test',\n","                   HISTORY = HISTORY)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["diff!!!\n","Setting up datagens...\n","Found 44393 images belonging to 2 classes.\n","Found 11097 images belonging to 2 classes.\n","Class weights = {0: 4.930691309756531, 1: 0.5564246034133526}\n","Early stopping in 10\n","Epoch 1/100\n","693/693 [==============================] - ETA: 0s - loss: 0.6922 - acc: 0.5160 - auc: 0.5341 - fp: 1021.4618 "],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gVARQyyYYlt9","executionInfo":{"status":"aborted","timestamp":1617970021441,"user_tz":-60,"elapsed":252212,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}}},"source":["# # General model settings\n","# IMG_HEIGHT, IMG_WIDTH = 71, 71\n","# EPOCHS = 5\n","# DATA_GENERATOR_SEED = 1337\n","# BATCH_SIZE = 64\n","# VALIDATION_SPLIT = 0.2\n","\n","# tf.random.set_seed(DATA_GENERATOR_SEED)\n","# seed(DATA_GENERATOR_SEED)\n","\n","# for EXPERIMENT_TYPE in tqdm(['optimiser', 'structure']):\n","#     for df_name, DF_TYPE in tqdm([('Random_Frame', 'rnd'), ('Frame_Averaging', 'avg'), ('Frame_Difference', 'diff')]):\n","        \n","#         EXPERIMENT_NAME = f'Hyperband({EXPERIMENT_TYPE.title()})_{df_name}_Dataset'\n","#         EXPERIMENT_FOLDER_NAME = f'./Results/{EXPERIMENT_NAME}'\n","#         Path(EXPERIMENT_FOLDER_NAME).mkdir(parents=True, exist_ok=True)\n","#         print(EXPERIMENT_NAME)\n","\n","#         TRAIN_VAL_DIR = f'./Celeb-DF-v2/Celeb-{DF_TYPE}-30'\n","\n","#         print('Defining train and validation datagens...')\n","#         TRAIN_DATAGEN = ImageDataGenerator(rescale = 1.0/255.0, horizontal_flip = True, fill_mode='nearest', validation_split = VALIDATION_SPLIT)\n","#         TRAIN_GENERATOR = TRAIN_DATAGEN.flow_from_directory(directory = TRAIN_VAL_DIR,\n","#                                                             batch_size = BATCH_SIZE,\n","#                                                             class_mode = 'binary', \n","#                                                             target_size = (IMG_HEIGHT, IMG_WIDTH),\n","#                                                             subset = 'training',\n","#                                                             seed = DATA_GENERATOR_SEED,\n","#                                                             follow_links = True)\n","\n","#         VAL_DATAGEN = ImageDataGenerator(rescale = 1.0/255.0, validation_split = VALIDATION_SPLIT)\n","#         VALIDATION_GENERATOR = TRAIN_DATAGEN.flow_from_directory(directory = TRAIN_VAL_DIR,\n","#                                                                  batch_size = BATCH_SIZE,\n","#                                                                  class_mode = 'binary', \n","#                                                                  target_size = (IMG_HEIGHT, IMG_WIDTH),\n","#                                                                  subset = 'validation',\n","#                                                                  seed = DATA_GENERATOR_SEED,\n","#                                                                  follow_links = True)\n","        \n","#         print('Calculating class weights')\n","#         train_gen_list = list(TRAIN_GENERATOR.classes)\n","#         val_gen_list = list(VALIDATION_GENERATOR.classes)\n","\n","#         train_neg, train_pos = train_gen_list.count(0), train_gen_list.count(1)\n","#         val_neg, val_pos = val_gen_list.count(0), val_gen_list.count(1)\n","\n","#         pos = train_pos + val_pos\n","#         neg = train_neg + val_neg\n","#         total = pos + neg\n","\n","#         weight_for_0 = (1.0 / neg) * (total) / 2.0 \n","#         weight_for_1 = (1.0 / pos) * (total) / 2.0\n","\n","#         CLASS_WEIGHT = {0: weight_for_0, 1: weight_for_1}\n","#         print(f'Class weights = {CLASS_WEIGHT}')\n","\n","#         print(f'Setting up Hyperband with {EXPERIMENT_TYPE}')\n","#         tuner = Hyperband(eval(f'experiment_tuner_models.{EXPERIMENT_TYPE}_experiment_model'),\n","#                           objective = Objective('val_auc', direction = 'max'),\n","#                           max_epochs = EPOCHS,\n","#                           directory = './Results/',\n","#                           project_name = f'{EXPERIMENT_NAME}/',\n","#                           overwrite = True)\n","\n","#         tuner.search_space_summary()\n","#         tuner.search(TRAIN_GENERATOR,\n","#                      validation_data = VALIDATION_GENERATOR,\n","#                      epochs = EPOCHS,\n","#                      steps_per_epoch = TRAIN_GENERATOR.n // TRAIN_GENERATOR.batch_size,\n","#                      validation_steps = VALIDATION_GENERATOR.n // VALIDATION_GENERATOR.batch_size,\n","#                      class_weight = CLASS_WEIGHT,\n","#                      verbose = 1,\n","#                      callbacks = [EarlyStopping(monitor = 'val_auc',\n","#                                                 patience = EPOCHS//5+1,\n","#                                                 mode = 'max',\n","#                                                 verbose = 1)])\n","#         print(tuner.results_summary())\n","#         print(tuner.get_best_models())\n","\n","#         print(f'Saving tuner summary file to {EXPERIMENT_FOLDER_NAME}/{EXPERIMENT_NAME}_tuner.txt')\n","#         tuner_file = open(f'{EXPERIMENT_FOLDER_NAME}/{EXPERIMENT_NAME}_tuner.txt', 'w')\n","#         tuner_file.write(tuner.results_summary())\n","#         tuner_file.write(tuner.get_best_models())\n","#     #     summary_file.write(str(tuner.results_summary()).replace(', \\'', ':\\n\\n'))\n","#     #     summary_file.write(str(tuner.get_best_models()).replace(', \\'', ':\\n\\n'))\n","#         tuner_file.close()\n","\n","#         evaluate_model(TEST_MODEL = tuner.get_best_models()[0],\n","#                        EXPERIMENT_NAME = EXPERIMENT_NAME,\n","#                        TEST_DIR = f'./Celeb-DF-v2/Celeb-{DF_TYPE}-30-test',\n","#                        HISTORY = tuner.get_best_models()[0].history)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gv9rvVYsYlt_","executionInfo":{"status":"aborted","timestamp":1617970021443,"user_tz":-60,"elapsed":252209,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}}},"source":[""],"execution_count":null,"outputs":[]}]}