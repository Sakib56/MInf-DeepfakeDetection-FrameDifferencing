{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Hyperband Experiments.ipynb","provenance":[{"file_id":"1MCT9KN8njl1dziDoGwZm63mavSfVBFlk","timestamp":1617137055089}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.6"}},"cells":[{"cell_type":"code","metadata":{"id":"Lem7SXpH-QOW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617959816392,"user_tz":-60,"elapsed":1768,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}},"outputId":"f14a7483-8eb3-408d-8c80-6272bf256491"},"source":["# For Google Colab use\n","try:\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount=True)\n","    %cd '/content/drive/MyDrive/Colab Notebooks/MInf-DeepfakeDetection-FrameDifferencing'    \n","except ModuleNotFoundError:\n","    pass"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Colab Notebooks/MInf-DeepfakeDetection-FrameDifferencing\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UhCyJkhz-SS7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617959826566,"user_tz":-60,"elapsed":11931,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}},"outputId":"6472ee1c-216c-4403-d276-2fd11998710e"},"source":["# Imports\n","from __future__ import division\n","\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n","from numpy.random import seed\n","from time import time\n","from pathlib import Path\n","\n","import tensorflow as tf\n","\n","import keras\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras import layers, Model\n","from keras.callbacks import EarlyStopping\n","from keras.optimizers import Adam, RMSprop, SGD\n","from keras.applications import Xception\n","from keras import metrics\n","from keras.losses import BinaryCrossentropy\n","from keras import backend as K\n","\n","!pip install tensorflow_addons;\n","from tensorflow_addons.losses import SigmoidFocalCrossEntropy\n","\n","!pip install -U keras-tuner;\n","from kerastuner.tuners import Hyperband\n","from kerastuner.engine.hypermodel import HyperModel\n","from kerastuner.engine.hyperparameters import HyperParameters\n","from kerastuner import Objective\n","\n","!pip install face_recognition;\n","from Util import pipeline\n","from Util import experiment_tuner_models"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.7/dist-packages (0.12.1)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n","Requirement already up-to-date: keras-tuner in /usr/local/lib/python3.7/dist-packages (1.0.2)\n","Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.16.0)\n","Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n","Requirement already satisfied, skipping upgrade: colorama in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.4.4)\n","Requirement already satisfied, skipping upgrade: tabulate in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.8.9)\n","Requirement already satisfied, skipping upgrade: terminaltables in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (3.1.0)\n","Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.4.1)\n","Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (20.9)\n","Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (4.41.1)\n","Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.19.5)\n","Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.22.2.post1)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2020.12.5)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n","Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (2.4.7)\n","Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->keras-tuner) (1.0.1)\n","Requirement already satisfied: face_recognition in /usr/local/lib/python3.7/dist-packages (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from face_recognition) (1.19.5)\n","Requirement already satisfied: face-recognition-models>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (0.3.0)\n","Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (19.18.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n","Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I43exceKl-mT","executionInfo":{"status":"ok","timestamp":1617959826574,"user_tz":-60,"elapsed":11932,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}}},"source":["def evaluate_model(TEST_MODEL, EXPERIMENT_NAME:str, TEST_DIR:str, BACTH_SIZE:int=64, \\\n","                   IMG_HEIGHT:int=256, IMG_WIDTH:int=256, DATA_GENERATOR_SEED:int=1337, \\\n","                   HISTORY=None):\n","    \n","    from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n","    \n","    EXPERIMENT_NAME = EXPERIMENT_NAME.replace(\" \", \"_\")\n","    EXPERIMENT_FOLDER_NAME = f'./Results/{EXPERIMENT_NAME}'\n","    Path(EXPERIMENT_FOLDER_NAME).mkdir(parents=True, exist_ok=True)\n","\n","    # Define testing datagen\n","    print('Defining testing datagen...')\n","    TEST_DATAGEN = ImageDataGenerator(rescale=1./255)\n","    TEST_GENERATOR = TEST_DATAGEN.flow_from_directory(directory = TEST_DIR,\n","                                                      batch_size = BACTH_SIZE,\n","                                                      class_mode = 'binary', \n","                                                      target_size =  (IMG_HEIGHT, IMG_WIDTH),                                \n","                                                      seed = DATA_GENERATOR_SEED,\n","                                                      follow_links = True)\n","\n","    # Evaluate test set and get metrics, e.g. loss\n","    print('Evaluating test set and getting metrics...')\n","    TEST_HISORY = TEST_MODEL.evaluate(TEST_GENERATOR,\n","                                      batch_size = BACTH_SIZE,\n","                                      return_dict = True)\n","    TEST_GENERATOR.reset()\n","\n","    # Get predictions and ground truths\n","    print('Predicting on test set...')\n","    Y_pred = (TEST_MODEL.predict(TEST_GENERATOR)).ravel()\n","    Y_true = (TEST_GENERATOR.classes).ravel()\n","\n","    # Plot AUC and save plot\n","    print('Plotting AUC...')\n","    fpr, tpr, _ = roc_curve(Y_true, Y_pred)\n","    try:\n","        roc_auc = auc(fpr, tpr)\n","    except:\n","        roc_auc = None\n","        roc_auc = auc(fpr, tpr)\n","\n","    plt.figure()\n","    plt.plot(fpr, tpr, color='magenta', lw=2, label='ROC curve (area = %0.3f)' % roc_auc)\n","    plt.plot([0, 1], [0, 1], color='black', lw=2, linestyle='--')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.01])\n","    plt.xlabel('False Positive Rate (Fake Incorrectly Classed Rate)')\n","    plt.ylabel('True Positive Rate (Fake Correctly Classed Rate)')\n","    plt.title(f'{EXPERIMENT_NAME.replace(\"_\", \" \")} ROC')\n","    plt.legend(loc=\"lower right\")\n","    print(f'Saving AUC to {EXPERIMENT_FOLDER_NAME}/{EXPERIMENT_NAME}_AUC.pdf')\n","    plt.savefig(f'{EXPERIMENT_FOLDER_NAME}/{EXPERIMENT_NAME}_AUC.pdf')\n","\n","    # Create file, write metrics\n","    print(f'Saving summary file to {EXPERIMENT_FOLDER_NAME}/{EXPERIMENT_NAME}_summary.txt')\n","    summary_file = open(f'{EXPERIMENT_FOLDER_NAME}/{EXPERIMENT_NAME}_summary.txt', 'w')\n","    summary_file.write(str(TEST_HISORY).replace(', \\'', ':\\n\\n'))\n","    print(str(TEST_HISORY).replace(', \\'', ':\\n'))\n","\n","    # find classification thershold which results in max auc\n","    roc_aucs = []\n","    for thrshld in map(lambda x: x/1000.0, range(0, 1000+1)):\n","        fpr, tpr, _ = roc_curve(Y_true, (Y_pred >= thrshld).astype(int))\n","        roc_aucs.append((auc(fpr, tpr), thrshld))\n","    max_auc_thrshld = max(roc_aucs)[1]\n","\n","    # use max auc classification thershold to get confusion matrix and classification report\n","    y_pred = (Y_pred >= max_auc_thrshld).astype(int)\n","    summary_output_text = f'''\\n\\nTHRESHOLD = {max_auc_thrshld}\n","    \\nCONFUSION MATRIX\\n{confusion_matrix(Y_true, y_pred)}\n","    \\nCLASSIFICATION REPORT\\n{classification_report(Y_true, y_pred, target_names = [\"REAL\", \"FAKE\"])}\n","    _____________________________________________________\\n'''\n","    summary_file.write(summary_output_text)\n","    summary_file.write(f'''\\n{list(zip(Y_true, Y_pred))}''')\n","    print(summary_output_text)\n","    summary_file.close()\n","\n","    # plot history (of training), if provided\n","    if HISTORY is not None:\n","        print('Plotting training history x4 plots...')\n","        acc = HISTORY.history['acc']\n","        auc = HISTORY.history['auc']\n","        loss = HISTORY.history['loss']\n","        fp = HISTORY.history['fp']\n","\n","        val_acc = HISTORY.history['val_acc']\n","        val_auc = HISTORY.history['val_auc']\n","        val_loss = HISTORY.history['val_loss']\n","        val_fp = HISTORY.history['val_fp']\n","\n","        epochs = range(len(acc))\n","        fig, axs = plt.subplots(2, 2, figsize=(10,10))\n","        fig.suptitle(f'{EXPERIMENT_NAME.replace(\"_\", \" \")} Train & Validation Metrics')\n","\n","        axs[0, 0].plot(epochs, acc, 'r', label='Train Binary Accuracy')\n","        axs[0, 0].plot(epochs, val_acc, 'b', label='Validation Binary Accuracy')\n","        axs[0, 0].set_title('Binary Accuracy')\n","        axs[0, 0].legend()\n","\n","        axs[0, 1].plot(epochs, loss, 'r', label='Train Loss')\n","        axs[0, 1].plot(epochs, val_loss, 'b', label='Validation Loss')\n","        axs[0, 1].set_title('Loss')\n","        axs[0, 1].legend()\n","\n","        axs[1, 0].plot(epochs, auc, 'r', label='Train AUC')\n","        axs[1, 0].plot(epochs, val_auc, 'b', label='Validation AUC')\n","        axs[1, 0].set_title('AUC')\n","        axs[1, 0].legend()\n","\n","        axs[1, 1].plot(epochs, fp, 'r', label='Train False Positives')\n","        axs[1, 1].plot(epochs, val_fp, 'b', label='Validation False Positives')\n","        axs[1, 1].set_title('False Positives')\n","        axs[1, 1].legend()\n","        \n","        print(f'Saving history plots to {EXPERIMENT_FOLDER_NAME}/{EXPERIMENT_NAME}_history.pdf')\n","        fig.savefig(f'{EXPERIMENT_FOLDER_NAME}/{EXPERIMENT_NAME}_history.pdf')\n","    \n","    return Y_true, Y_pred"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"TCZT0SbEAcdA","executionInfo":{"status":"ok","timestamp":1617959826578,"user_tz":-60,"elapsed":11931,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}}},"source":["# General model settings\n","IMG_HEIGHT, IMG_WIDTH = 71, 71\n","EPOCHS = 5\n","DATA_GENERATOR_SEED = 1337\n","BATCH_SIZE = 64\n","VALIDATION_SPLIT = 0.2\n","\n","tf.random.set_seed(DATA_GENERATOR_SEED)\n","seed(DATA_GENERATOR_SEED)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JX0a9bICHlYh","outputId":"b35e68b5-f757-4589-9887-51597fcfb137"},"source":["for EXPERIMENT_TYPE in tqdm(['loss', 'optimiser', 'structure'][::-1]):\n","    for df_name, DF_TYPE in tqdm([('Random_Frame', 'rnd'), ('Frame_Averaging', 'avg'), ('Frame_Difference', 'diff')]):\n","        \n","        EXPERIMENT_NAME = f'Hyperband({EXPERIMENT_TYPE.title()})_{df_name}_dataset'\n","        EXPERIMENT_FOLDER_NAME = f'./Results/{EXPERIMENT_NAME}'\n","        Path(EXPERIMENT_FOLDER_NAME).mkdir(parents=True, exist_ok=True)\n","        print(EXPERIMENT_NAME)\n","\n","        TRAIN_VAL_DIR = f'./Celeb-DF-v2/Celeb-{DF_TYPE}-30'\n","\n","        print('Defining train and validation datagens...')\n","        TRAIN_DATAGEN = ImageDataGenerator(rescale = 1.0/255.0, horizontal_flip = True, fill_mode='nearest', validation_split = VALIDATION_SPLIT)\n","        TRAIN_GENERATOR = TRAIN_DATAGEN.flow_from_directory(directory = TRAIN_VAL_DIR,\n","                                                            batch_size = BATCH_SIZE,\n","                                                            class_mode = 'binary', \n","                                                            target_size = (IMG_HEIGHT, IMG_WIDTH),\n","                                                            subset = 'training',\n","                                                            seed = DATA_GENERATOR_SEED,\n","                                                            follow_links = True)\n","\n","        VAL_DATAGEN = ImageDataGenerator(rescale = 1.0/255.0, validation_split = VALIDATION_SPLIT)\n","        VALIDATION_GENERATOR = TRAIN_DATAGEN.flow_from_directory(directory = TRAIN_VAL_DIR,\n","                                                                 batch_size = BATCH_SIZE,\n","                                                                 class_mode = 'binary', \n","                                                                 target_size = (IMG_HEIGHT, IMG_WIDTH),\n","                                                                 subset = 'validation',\n","                                                                 seed = DATA_GENERATOR_SEED,\n","                                                                 follow_links = True)\n","        \n","        print('Calculating class weights')\n","        train_gen_list = list(TRAIN_GENERATOR.classes)\n","        val_gen_list = list(VALIDATION_GENERATOR.classes)\n","\n","        train_neg, train_pos = train_gen_list.count(0), train_gen_list.count(1)\n","        val_neg, val_pos = val_gen_list.count(0), val_gen_list.count(1)\n","\n","        pos = train_pos + val_pos\n","        neg = train_neg + val_neg\n","        total = pos + neg\n","\n","        weight_for_0 = (1.0 / neg) * (total) / 2.0 \n","        weight_for_1 = (1.0 / pos) * (total) / 2.0\n","\n","        CLASS_WEIGHT = {0: weight_for_0, 1: weight_for_1}\n","        print(f'Class weights = {CLASS_WEIGHT}')\n","\n","        print(f'Setting up Hyperband with {EXPERIMENT_TYPE}')\n","        tuner = Hyperband(eval(f'experiment_tuner_models.{EXPERIMENT_TYPE}_experiment_model'),\n","                          objective = Objective('val_auc', direction = 'max'),\n","                          max_epochs = EPOCHS,\n","                          directory = EXPERIMENT_FOLDER_NAME,\n","                          project_name = f'{EXPERIMENT_FOLDER_NAME}/',\n","                          overwrite = True)\n","\n","        tuner.search_space_summary()\n","        tuner.search(TRAIN_GENERATOR,\n","                     validation_data = VALIDATION_GENERATOR,\n","                     epochs = EPOCHS,\n","                     steps_per_epoch = TRAIN_GENERATOR.n // TRAIN_GENERATOR.batch_size,\n","                     validation_steps = VALIDATION_GENERATOR.n // VALIDATION_GENERATOR.batch_size,\n","                     class_weight = CLASS_WEIGHT,\n","                     verbose = 1,\n","                     callbacks = [EarlyStopping(monitor = 'val_auc',\n","                                                patience = EPOCHS//5+1,\n","                                                mode = 'max',\n","                                                verbose = 1)])\n","        print(tuner.results_summary())\n","        print(tuner.get_best_models())\n","\n","        print(f'Saving tuner summary file to {EXPERIMENT_FOLDER_NAME}/{EXPERIMENT_NAME}_tuner.txt')\n","        tuner_file = open(f'{EXPERIMENT_FOLDER_NAME}/{EXPERIMENT_NAME}_tuner.txt', 'w')\n","        tuner_file.write(tuner.results_summary())\n","        tuner_file.write(tuner.get_best_models())\n","    #     summary_file.write(str(tuner.results_summary()).replace(', \\'', ':\\n\\n'))\n","    #     summary_file.write(str(tuner.get_best_models()).replace(', \\'', ':\\n\\n'))\n","        tuner_file.close()\n","\n","        evaluate_model(TEST_MODEL = tuner.get_best_models()[0],\n","                       EXPERIMENT_NAME = EXPERIMENT_NAME,\n","                       TEST_DIR = f'./Celeb-DF-v2/Celeb-{DF_TYPE}-30-test',\n","                       HISTORY = tuner.get_best_models()[0].history)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  0%|          | 0/3 [00:00<?, ?it/s]\n","  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["Hyperband(Structure)_Random_Frame_dataset\n","Defining train and validation datagens...\n","Found 44393 images belonging to 2 classes.\n","Found 11097 images belonging to 2 classes.\n","Calculating class weights\n","Class weights = {0: 4.930691309756531, 1: 0.5564246034133526}\n","Setting up Hyperband with structure\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n","83689472/83683744 [==============================] - 0s 0us/step\n","Search space summary\n","Default search space size: 2\n","number_of_dense_dropout_blocks (Int)\n","{'default': None, 'conditions': [], 'min_value': 0, 'max_value': 2, 'step': 1, 'sampling': None}\n","penultimate_dense_unit (Int)\n","{'default': None, 'conditions': [], 'min_value': 1024, 'max_value': 4096, 'step': 512, 'sampling': None}\n","\n","Search: Running Trial #1\n","\n","Hyperparameter    |Value             |Best Value So Far \n","number_of_dense...|0                 |?                 \n","penultimate_den...|3072              |?                 \n","tuner/epochs      |2                 |?                 \n","tuner/initial_e...|0                 |?                 \n","tuner/bracket     |1                 |?                 \n","tuner/round       |0                 |?                 \n","\n","Epoch 1/2\n","192/693 [=======>......................] - ETA: 2:46:19 - loss: 0.9400 - acc: 0.5681 - auc: 0.5554 - fp: 289.5625"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"V8nqknPJbLwV"},"source":[""],"execution_count":null,"outputs":[]}]}