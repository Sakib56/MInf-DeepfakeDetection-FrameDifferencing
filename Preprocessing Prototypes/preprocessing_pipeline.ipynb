{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"colab":{"name":"preprocessing_pipeline.ipynb","provenance":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-FFpCLmJ1_9v","executionInfo":{"status":"ok","timestamp":1611952788023,"user_tz":0,"elapsed":4095,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}},"outputId":"47e2addb-b15c-405c-f635-e6fd578fd3ae"},"source":["!pip install face_recognition\r\n","\r\n","from google.colab import drive\r\n","drive.flush_and_unmount()\r\n","drive.mount('/content/drive/', force_remount=True)\r\n","\r\n","import os\r\n","os.chdir(os.path.join(os.getcwd(), 'drive', 'MyDrive', 'Colab Notebooks', 'DeepFake Detector'))\r\n","print(f'current cwd = {os.getcwd()}')"],"id":"-FFpCLmJ1_9v","execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: face_recognition in /usr/local/lib/python3.6/dist-packages (1.3.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from face_recognition) (7.0.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from face_recognition) (1.19.5)\n","Requirement already satisfied: face-recognition-models>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (0.3.0)\n","Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (7.1.2)\n","Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (19.18.0)\n","Mounted at /content/drive/\n","current cwd = /content/drive/MyDrive/Colab Notebooks/DeepFake Detector\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3Ixxd_cU16yM","executionInfo":{"status":"ok","timestamp":1611952798192,"user_tz":0,"elapsed":432,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}}},"source":["import os\n","\n","from tqdm import tqdm\n","from PIL import Image\n","from heapq import nsmallest\n","from math import ceil\n","from random import randint, seed\n","from time import time"],"id":"3Ixxd_cU16yM","execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"wbcdSjTi16yW","executionInfo":{"status":"ok","timestamp":1611952809654,"user_tz":0,"elapsed":9021,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}}},"source":["from pipeline import *\n","\n","seed(0)\n","\n","real_video_dir_path = os.path.join('.', 'Celeb-DF-v2', 'Celeb-real')\n","fake_video_dir_path = os.path.join('.', 'Celeb-DF-v2', 'Celeb-synthesis')\n","\n","video_dir_path = real_video_dir_path\n","video_listdir = os.listdir(video_dir_path)"],"id":"wbcdSjTi16yW","execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":398},"id":"9yBeC9hv16yX","executionInfo":{"status":"error","timestamp":1611953505553,"user_tz":0,"elapsed":693429,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}},"outputId":"36e5e80e-60a5-4fe0-b5c7-c9f058f1176b"},"source":["for video_name in tqdm(video_listdir):\n","    start_time = time()\n","    video = os.path.join(video_dir_path, video_name)\n","\n","    frames = get_every_frame(video, interval=1)\n","    face_coordinates = get_face_locations(frames)\n","    centroid = get_centroid(face_coordinates)\n","    dist_from_centroid = get_distance_from_centroid(centroid,\n","                                                    face_coordinates)\n","\n","    movement_thershold = nsmallest(4, set(filter(bool, dist_from_centroid)))[-1]\n","\n","    stable_faces = get_stable_faces(movement_thershold,\n","                                dist_from_centroid, \n","                                face_coordinates, \n","                                frames, \n","                                zoomed=False)\n","\n","    number_of_frames_w_faces = len(stable_faces)\n","    sections = 6\n","    differencing_interval = ceil(number_of_frames_w_faces/sections)\n","\n","    differenced_face = difference(stable_faces, interval=differencing_interval)\n","    Image.fromarray(differenced_face, mode='RGB').save(\n","        os.path.join(f'{video_dir_path}-diff', f'{video_name}.png'),'PNG')\n","\n","    average_face = average(stable_faces)\n","    Image.fromarray(average_face, mode='RGB').save(\n","        os.path.join(f'{video_dir_path}-avg', f'{video_name}.png'),'PNG')\n","\n","    random_face = stable_faces[randint(0, number_of_frames_w_faces-1)]\n","    Image.fromarray(random_face, mode='RGB').save(\n","        os.path.join(f'{video_dir_path}-rnd', f'{video_name}.png'),'PNG')\n","\n","    # print(f'\\n{video_name} pre-processed in {time()-start_time:.2f}s')"],"id":"9yBeC9hv16yX","execution_count":5,"outputs":[{"output_type":"stream","text":["  1%|          | 6/590 [11:12<18:48:29, 115.94s/it]"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-e075571a57fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_every_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mface_coordinates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_face_locations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mcentroid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_centroid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface_coordinates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     dist_from_centroid = get_distance_from_centroid(centroid,\n","\u001b[0;32m/content/drive/My Drive/Colab Notebooks/DeepFake Detector/pipeline.py\u001b[0m in \u001b[0;36mget_face_locations\u001b[0;34m(frames)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mface_coordinates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mcoordinates_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface_locations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcoordinates_found\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoordinates_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mface_coordinates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoordinates_found\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/face_recognition/api.py\u001b[0m in \u001b[0;36mface_locations\u001b[0;34m(img, number_of_times_to_upsample, model)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_trim_css_to_bounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_rect_to_css\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mface\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_raw_face_locations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_times_to_upsample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cnn\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_trim_css_to_bounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_rect_to_css\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mface\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_raw_face_locations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_times_to_upsample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/face_recognition/api.py\u001b[0m in \u001b[0;36m_raw_face_locations\u001b[0;34m(img, number_of_times_to_upsample, model)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcnn_face_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_times_to_upsample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mface_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_times_to_upsample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"ofI-G0mE22cg"},"source":[""],"id":"ofI-G0mE22cg","execution_count":null,"outputs":[]}]}