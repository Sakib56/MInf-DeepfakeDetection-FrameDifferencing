{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"hyperband_search.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.6"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Lem7SXpH-QOW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614200303992,"user_tz":0,"elapsed":1899,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}},"outputId":"3aa572da-e7a8-4147-db96-c23a4c0e75bc"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OuYK9b0K-WPQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614200303994,"user_tz":0,"elapsed":1884,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}},"outputId":"68a0c190-f72a-48ae-9a85-6bf4a9129864"},"source":["%cd '/content/drive/MyDrive/Colab Notebooks/DeepFake Detector'"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/DeepFake Detector\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UhCyJkhz-SS7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614200309027,"user_tz":0,"elapsed":6906,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}},"outputId":"8c2fa80b-46f6-4c1e-fcbc-b42b10a9097d"},"source":["from __future__ import division\n","\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n","from numpy.random import seed\n","\n","import tensorflow as tf\n","\n","import keras\n","from keras import preprocessing\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras import layers, Model\n","from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n","from keras.optimizers import *\n","from keras.applications import *\n","from keras import metrics\n","from keras.losses import BinaryCrossentropy\n","from keras import backend as K\n","\n","!pip install -U keras-tuner\n","from kerastuner.tuners import RandomSearch, Hyperband\n","from kerastuner.engine.hypermodel import HyperModel\n","from kerastuner.engine.hyperparameters import HyperParameters\n","from kerastuner import Objective"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already up-to-date: keras-tuner in /usr/local/lib/python3.7/dist-packages (1.0.2)\n","Requirement already satisfied, skipping upgrade: colorama in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.4.4)\n","Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (20.9)\n","Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n","Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.16.0)\n","Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.4.1)\n","Requirement already satisfied, skipping upgrade: tabulate in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.8.8)\n","Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.22.2.post1)\n","Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (4.41.1)\n","Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.19.5)\n","Requirement already satisfied, skipping upgrade: terminaltables in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (3.1.0)\n","Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (2.4.7)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2020.12.5)\n","Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->keras-tuner) (1.0.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aQEYM2RvbjwM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614200309510,"user_tz":0,"elapsed":7377,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}},"outputId":"55798a6a-2981-4990-b53f-a04edd346188"},"source":["%tensorflow_version 2.x\r\n","device_name = tf.test.gpu_device_name()\r\n","if device_name != '/device:GPU:0':\r\n","  raise SystemError('GPU device not found')\r\n","print('Found GPU at: {}'.format(device_name))\r\n","print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n","Num GPUs Available:  1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TCZT0SbEAcdA","executionInfo":{"status":"ok","timestamp":1614200309511,"user_tz":0,"elapsed":7368,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}}},"source":["IMG_HEIGHT, IMG_WIDTH = 128, 128\r\n","EPOCHS = 30\r\n","DATA_GENERATOR_SEED = 1337\r\n","BACTH_SIZE = 128\r\n","VALIDATION_SPLIT = 0\r\n","LEARNING_RATE = 1e-3\r\n","\r\n","tf.random.set_seed(DATA_GENERATOR_SEED)\r\n","seed(DATA_GENERATOR_SEED)\r\n","\r\n","DF_TYPE = 'diff'\r\n","LOSS = BinaryCrossentropy()\r\n","PRE_TRAINED_MODEL = 'Xception'\r\n","OPTIMIZERZ = 'SGD'\r\n","\r\n","TRAIN_VAL_DIR = f'./Celeb-DF-v2/Celeb-{DF_TYPE}'\r\n","if 'bal' in TRAIN_VAL_DIR:\r\n","    TEST_DIR = TRAIN_VAL_DIR.replace('bal', 'test')\r\n","else:\r\n","    TEST_DIR = f'{TRAIN_VAL_DIR}-test'"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C_cifuqS8bV5","executionInfo":{"status":"ok","timestamp":1614200349223,"user_tz":0,"elapsed":47073,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}},"outputId":"5a413d9c-62b6-4345-cc12-930905280732"},"source":["TRAIN_DATAGEN = ImageDataGenerator(rescale = 1./255.,\r\n","                                   rotation_range = 20,\r\n","                                   width_shift_range = 0.2,\r\n","                                   height_shift_range = 0.2,\r\n","                                   shear_range = 0.15,\r\n","                                   zoom_range = 0.15,\r\n","                                   horizontal_flip = True,\r\n","                                   fill_mode='nearest',\r\n","                                   validation_split = VALIDATION_SPLIT)\r\n","\r\n","VAL_DATAGEN = ImageDataGenerator(rescale = 1.0/255., \r\n","                                 validation_split = VALIDATION_SPLIT)\r\n","\r\n","TEST_DATAGEN = ImageDataGenerator(rescale = 1.0/255.)\r\n","\r\n","TRAIN_GENERATOR = TRAIN_DATAGEN.flow_from_directory(directory = TRAIN_VAL_DIR,\r\n","                                                    batch_size = BACTH_SIZE,\r\n","                                                    class_mode = 'binary', \r\n","                                                    target_size = (IMG_HEIGHT, IMG_WIDTH),\r\n","                                                    subset = 'training',\r\n","                                                    seed = DATA_GENERATOR_SEED)\r\n","\r\n","VALIDATION_GENERATOR = TRAIN_DATAGEN.flow_from_directory(directory = TRAIN_VAL_DIR,\r\n","                                                         batch_size = BACTH_SIZE,\r\n","                                                         class_mode = 'binary', \r\n","                                                         target_size = (IMG_HEIGHT, IMG_WIDTH),\r\n","                                                         subset = 'validation',\r\n","                                                         seed = DATA_GENERATOR_SEED)\r\n","\r\n","TEST_GENERATOR = TEST_DATAGEN.flow_from_directory(directory = TEST_DIR,\r\n","                                                  batch_size = BACTH_SIZE,\r\n","                                                  class_mode = 'binary', \r\n","                                                  target_size = (IMG_HEIGHT, IMG_WIDTH),                                \r\n","                                                  seed = DATA_GENERATOR_SEED)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Found 4577 images belonging to 2 classes.\n","Found 0 images belonging to 2 classes.\n","Found 1652 images belonging to 2 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nLlAOc-Q9YGg","executionInfo":{"status":"ok","timestamp":1614200349225,"user_tz":0,"elapsed":47063,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}},"outputId":"fdfda3f4-ecfd-4ce9-a4e6-191f5a0b223a"},"source":["train_gen_list = list(TRAIN_GENERATOR.classes)\r\n","val_gen_list = list(VALIDATION_GENERATOR.classes)\r\n","test_gen_list = list(TEST_GENERATOR.classes)\r\n","\r\n","train_neg, train_pos = train_gen_list.count(0), train_gen_list.count(1)\r\n","val_neg, val_pos = val_gen_list.count(0), val_gen_list.count(1)\r\n","test_neg, test_pos = test_gen_list.count(0), test_gen_list.count(1)\r\n","\r\n","print(f'\\nTRAIN\\nReal samples = {train_neg}\\nFake samples = {train_pos}')\r\n","print(f'\\nVALIDATION\\nReal samples = {val_neg}\\nFake samples = {val_pos}')\r\n","print(f'\\nTEST\\nReal samples = {test_neg}\\nFake samples = {test_pos}')\r\n","\r\n","pos = train_pos + val_pos\r\n","neg = train_neg + val_neg\r\n","total = pos + neg\r\n","\r\n","weight_for_0 = (1 / neg)*(total)/2.0 \r\n","weight_for_1 = (1 / pos)*(total)/2.0\r\n","\r\n","CLASS_WEIGHT = {0: weight_for_0, 1: weight_for_1}\r\n","\r\n","print(f'\\nWeight for Real = {weight_for_0:.5f}')\r\n","print(f'Weight for Fake = {weight_for_1:.5f}\\n')\r\n","\r\n","STEP_SIZE_TRAIN = TRAIN_GENERATOR.n//TRAIN_GENERATOR.batch_size"],"execution_count":7,"outputs":[{"output_type":"stream","text":["\n","TRAIN\n","Real samples = 422\n","Fake samples = 4155\n","\n","VALIDATION\n","Real samples = 0\n","Fake samples = 0\n","\n","TEST\n","Real samples = 168\n","Fake samples = 1484\n","\n","Weight for Real = 5.42299\n","Weight for Fake = 0.55078\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"P-U_x0F99J4m","executionInfo":{"status":"ok","timestamp":1614200349226,"user_tz":0,"elapsed":47057,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}}},"source":["def build_model(hp):\r\n","    PRE_TRAINED_MODEL = Xception(input_shape = (IMG_HEIGHT,IMG_WIDTH,3),\r\n","                                 include_top = False,\r\n","                                 pooling = 'avg',\r\n","                                 weights = 'imagenet')\r\n","    \r\n","    for layer in PRE_TRAINED_MODEL.layers:\r\n","        layer.trainable = False\r\n","\r\n","    x = layers.Flatten()(PRE_TRAINED_MODEL.output)\r\n","    for i in range(hp.Int('N_LAYERS', min_value = 0, max_value = 10)):\r\n","        x = layers.Dense(hp.Int(f'DENSE_UNITS_{i}', min_value = 1024, max_value = 3584, step = 256), activation = 'relu')(x)\r\n","        x = layers.Dropout(hp.Float(f'DROPOUT_PROB_{i}', min_value = 0, max_value = 0.35, step = 0.05))(x)\r\n","    x = layers.Dense(hp.Int(f'DENSE_UNITS_-1', min_value = 1024, max_value = 3584, step = 256), activation = 'relu')(x)\r\n","    x = layers.Dense(1, activation = 'sigmoid')(x)\r\n","\r\n","    MODEL = Model(PRE_TRAINED_MODEL.input, x)\r\n","\r\n","    MODEL.compile(optimizer = SGD(learning_rate = LEARNING_RATE,\r\n","                                  momentum = 0.9),\r\n","                loss = BinaryCrossentropy(label_smoothing = hp.Float(f'LABEL_SMOOTHING', min_value = 0, max_value = 0.6, step = 0.05)),\r\n","                metrics = [metrics.BinaryAccuracy(name = 'acc'),\r\n","                           metrics.AUC(name = 'auc'),\r\n","                           metrics.FalsePositives(name = 'fp')])\r\n","    \r\n","    return MODEL"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SBMuymsE-OrD","executionInfo":{"status":"ok","timestamp":1614200350855,"user_tz":0,"elapsed":48681,"user":{"displayName":"Sakib Ahamed","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghux0A3tJ8ak2hXsUY0-OJKE1g54h6Vq61r4o_n9GY=s64","userId":"01642899865297704166"}},"outputId":"2fb16a3f-8110-4ddd-d460-09f3278d86c7"},"source":["tuner = Hyperband(build_model,\r\n","                  objective = Objective('val_auc', direction = 'max'),\r\n","                  max_epochs = EPOCHS,\r\n","                  directory = 'tuner_logs',\r\n","                  project_name = f'df_{DF_TYPE}',\r\n","                  overwrite = True)\r\n","\r\n","tuner.search_space_summary()"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Search space summary\n","Default search space size: 3\n","N_LAYERS (Int)\n","{'default': None, 'conditions': [], 'min_value': 0, 'max_value': 10, 'step': 1, 'sampling': None}\n","DENSE_UNITS_-1 (Int)\n","{'default': None, 'conditions': [], 'min_value': 1024, 'max_value': 3584, 'step': 256, 'sampling': None}\n","LABEL_SMOOTHING (Float)\n","{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.6, 'step': 0.05, 'sampling': None}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kd-cS3heqBkb","outputId":"9f2fb3fc-4404-48c1-81b5-0a46a59ddc18"},"source":["tuner.search(TRAIN_GENERATOR,\r\n","             validation_data = TEST_GENERATOR,\r\n","             epochs = EPOCHS,\r\n","             steps_per_epoch = TRAIN_GENERATOR.n//TRAIN_GENERATOR.batch_size,\r\n","             validation_steps = TEST_GENERATOR.n//TEST_GENERATOR.batch_size,\r\n","             class_weight = CLASS_WEIGHT,\r\n","             verbose = 1,\r\n","             callbacks = [EarlyStopping(monitor = 'val_auc',\r\n","                                        patience = EPOCHS//10,\r\n","                                        mode = 'max',\r\n","                                        verbose = 1)])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Search: Running Trial #1\n","\n","Hyperparameter    |Value             |Best Value So Far \n","N_LAYERS          |3                 |?                 \n","DENSE_UNITS_-1    |2048              |?                 \n","LABEL_SMOOTHING   |0.55              |?                 \n","tuner/epochs      |2                 |?                 \n","tuner/initial_e...|0                 |?                 \n","tuner/bracket     |3                 |?                 \n","tuner/round       |0                 |?                 \n","\n","Epoch 1/2\n"," 2/35 [>.............................] - ETA: 52:22 - loss: 0.6751 - acc: 0.5684 - auc: 0.6699 - fp: 5.0000"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JX0a9bICHlYh"},"source":["tuner.results_summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7EE1xz3jqSpm"},"source":["BEST_MODEL = tuner.get_best_models()[0]\r\n","\r\n","Y_pred = BEST_MODEL.predict(TEST_GENERATOR, verbose = 1)\r\n","Y_true = TEST_GENERATOR.classes\r\n","\r\n","fpr, tpr, _ = roc_curve(Y_true, Y_pred)\r\n","try:\r\n","    roc_auc = auc(fpr, tpr)\r\n","except:\r\n","    pass\r\n","    \r\n","plt.figure()\r\n","lw = 2\r\n","plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.3f)' % roc_auc)\r\n","plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\r\n","plt.xlim([0.0, 1.0])\r\n","plt.ylim([0.0, 1.05])\r\n","plt.xlabel('False Positive Rate')\r\n","plt.ylabel('True Positive Rate')\r\n","plt.title('Receiver Operating Characteristic')\r\n","plt.legend(loc=\"lower right\")\r\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lMgbUE2L7W-m"},"source":["for thrshld in map(lambda x: x/100, range(45,56)):\r\n","    y_pred = (Y_pred > thrshld).astype(int)\r\n","    print(f'\\nTHRESHOLD = {thrshld}')\r\n","    print(f'\\nCONFUSION MATRIX\\n{confusion_matrix(Y_true, y_pred)}')\r\n","    print(f'\\nCLASSIFICATION REPORT\\n{classification_report(Y_true, y_pred, target_names = [\"REAL\", \"FAKE\"])}\\n\\n')\r\n","    print('________________________________________________________________\\n\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VUT4m8CSdkQU"},"source":["# IMG_HEIGHT, IMG_WIDTH = 299, 299\r\n","# EPOCHS = 30\r\n","# DATA_GENERATOR_SEED = 1337\r\n","# BACTH_SIZE = 256\r\n","# VALIDATION_SPLIT = 0\r\n","# LEARNING_RATE = 5e-2\r\n","\r\n","# DF_TYPE = 'diff' # 'rnd', 'diff-bal', 'avg-bal', 'rnd-bal']\r\n","\r\n","# TRAIN_VAL_DIR = f'./Celeb-DF-v2/Celeb-{DF_TYPE}'\r\n","# if 'bal' in TRAIN_VAL_DIR:\r\n","#     TEST_DIR = TRAIN_VAL_DIR.replace('bal', 'test')\r\n","# else:\r\n","#     TEST_DIR = f'{TRAIN_VAL_DIR}-test'\r\n","\r\n","# tf.random.set_seed(DATA_GENERATOR_SEED)\r\n","# seed(DATA_GENERATOR_SEED)\r\n","\r\n","# TRAIN_DATAGEN = ImageDataGenerator(rescale = 1./255.,\r\n","#                                    rotation_range = 20,\r\n","#                                    width_shift_range = 0.2,\r\n","#                                    height_shift_range = 0.2,\r\n","#                                    shear_range = 0.15,\r\n","#                                    zoom_range = 0.15,\r\n","#                                    horizontal_flip = True,\r\n","#                                    fill_mode='nearest',\r\n","#                                    validation_split = VALIDATION_SPLIT)\r\n","\r\n","# VAL_DATAGEN = ImageDataGenerator(rescale = 1.0/255., \r\n","#                                  validation_split = VALIDATION_SPLIT)\r\n","\r\n","# TEST_DATAGEN = ImageDataGenerator(rescale = 1.0/255.)\r\n","\r\n","# TRAIN_GENERATOR = TRAIN_DATAGEN.flow_from_directory(directory = TRAIN_VAL_DIR,\r\n","#                                                     batch_size = BACTH_SIZE,\r\n","#                                                     class_mode = 'binary', \r\n","#                                                     target_size = (IMG_HEIGHT, IMG_WIDTH),\r\n","#                                                     subset = 'training',\r\n","#                                                     seed = DATA_GENERATOR_SEED)\r\n","\r\n","# VALIDATION_GENERATOR = TRAIN_DATAGEN.flow_from_directory(directory = TRAIN_VAL_DIR,\r\n","#                                                          batch_size = BACTH_SIZE,\r\n","#                                                          class_mode = 'binary', \r\n","#                                                          target_size = (IMG_HEIGHT, IMG_WIDTH),\r\n","#                                                          subset = 'validation',\r\n","#                                                          seed = DATA_GENERATOR_SEED)\r\n","\r\n","# TEST_GENERATOR = TEST_DATAGEN.flow_from_directory(directory = TEST_DIR,\r\n","#                                                   batch_size = BACTH_SIZE,\r\n","#                                                   class_mode = 'binary', \r\n","#                                                   target_size = (IMG_HEIGHT, IMG_WIDTH),                                \r\n","#                                                   seed = DATA_GENERATOR_SEED)\r\n","# train_gen_list = list(TRAIN_GENERATOR.classes)\r\n","# val_gen_list = list(VALIDATION_GENERATOR.classes)\r\n","# test_gen_list = list(TEST_GENERATOR.classes)\r\n","\r\n","# train_neg, train_pos = train_gen_list.count(0), train_gen_list.count(1)\r\n","# val_neg, val_pos = val_gen_list.count(0), val_gen_list.count(1)\r\n","# test_neg, test_pos = test_gen_list.count(0), test_gen_list.count(1)\r\n","\r\n","# print(f'\\nTRAIN\\nReal samples = {train_neg}\\nFake samples = {train_pos}')\r\n","# print(f'\\nVALIDATION\\nReal samples = {val_neg}\\nFake samples = {val_pos}')\r\n","# print(f'\\nTEST\\nReal samples = {test_neg}\\nFake samples = {test_pos}')\r\n","\r\n","# pos = train_pos + val_pos\r\n","# neg = train_neg + val_neg\r\n","# total = pos + neg\r\n","\r\n","# weight_for_0 = (1 / neg)*(total)/2.0 \r\n","# weight_for_1 = (1 / pos)*(total)/2.0\r\n","\r\n","# CLASS_WEIGHT = {0: weight_for_0, 1: weight_for_1}\r\n","\r\n","# print(f'\\nWeight for Real = {weight_for_0:.5f}')\r\n","# print(f'Weight for Fake = {weight_for_1:.5f}\\n')\r\n","\r\n","# STEP_SIZE_TRAIN = TRAIN_GENERATOR.n//TRAIN_GENERATOR.batch_size\r\n","\r\n","# PRE_TRAINED_MODEL = Xception(input_shape = (IMG_HEIGHT,IMG_WIDTH,3),\r\n","#                                             include_top = False,\r\n","#                                             pooling = 'avg',\r\n","#                                             weights = 'imagenet')\r\n","# for layer in PRE_TRAINED_MODEL.layers:\r\n","#     layer.trainable = False\r\n","\r\n","# x = layers.Flatten()(PRE_TRAINED_MODEL.output)\r\n","# x = layers.Dense(2048, activation = 'relu')(x)\r\n","# x = layers.Dropout(0.2)(x)\r\n","# x = layers.Dense(1024, activation = 'relu')(x)\r\n","# x = layers.Dropout(0.2)(x)\r\n","# x = layers.Dense(512, activation = 'relu')(x)\r\n","# x = layers.Dropout(0.2)(x)\r\n","# x = layers.Dense(1, activation = 'sigmoid')(x)\r\n","\r\n","# MODEL = Model(PRE_TRAINED_MODEL.input, x)\r\n","\r\n","# MODEL.compile(optimizer = SGD(learning_rate = LEARNING_RATE,\r\n","#                               momentum = 0.9),\r\n","#               loss = BinaryCrossentropy(),\r\n","#               metrics = [metrics.BinaryAccuracy(name = 'acc'),\r\n","#                          metrics.AUC(name = 'auc'),\r\n","#                          metrics.FalsePositives(name = 'fp')])\r\n","\r\n","# HISTORY = MODEL.fit(TRAIN_GENERATOR,\r\n","#                     epochs = EPOCHS,\r\n","#                     steps_per_epoch = STEP_SIZE_TRAIN,\r\n","#                     validation_data = TEST_GENERATOR,\r\n","#                     validation_steps = TEST_GENERATOR.n//TEST_GENERATOR.batch_size,\r\n","#                     verbose = 1,\r\n","#                     class_weight = CLASS_WEIGHT,\r\n","#                     callbacks = [ReduceLROnPlateau(monitor = 'val_auc', \r\n","#                                                    patience = 1,\r\n","#                                                    factor = 0.0001**(1/float(EPOCHS)),\r\n","#                                                    verbose = 1,\r\n","#                                                    min_lr=1e-6)])\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8m6ImPfidcZk"},"source":["# MODEL.evaluate(TEST_GENERATOR)\r\n","\r\n","# STEP_SIZE_TEST = TEST_GENERATOR.n//TEST_GENERATOR.batch_size\r\n","# TEST_GENERATOR.reset()\r\n","# preds = MODEL.predict(TEST_GENERATOR, verbose = 1)\r\n","\r\n","# fpr, tpr, _ = roc_curve(TEST_GENERATOR.classes, preds)\r\n","# try:\r\n","#     roc_auc = auc(fpr, tpr)\r\n","# except:\r\n","#     pass\r\n","    \r\n","# plt.figure()\r\n","# lw = 2\r\n","# plt.plot(fpr, tpr, color='darkorange',\r\n","# lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\r\n","# plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\r\n","# plt.xlim([0.0, 1.0])\r\n","# plt.ylim([0.0, 1.05])\r\n","# plt.xlabel('False Positive Rate')\r\n","# plt.ylabel('True Positive Rate')\r\n","# plt.title('Receiver Operating Characteristic')\r\n","# plt.legend(loc=\"lower right\")\r\n","# plt.show()\r\n","\r\n","# acc = HISTORY.history['acc']\r\n","# auc = HISTORY.history['auc']\r\n","# loss = HISTORY.history['loss']\r\n","# fp = HISTORY.history['fp']\r\n","\r\n","# val_acc = HISTORY.history['val_acc']\r\n","# val_auc = HISTORY.history['val_auc']\r\n","# val_loss = HISTORY.history['val_loss']\r\n","# val_fp = HISTORY.history['val_fp']\r\n","\r\n","# epochs = range(len(acc))\r\n","\r\n","# fig, axs = plt.subplots(2, 2, figsize = (10,10))\r\n","\r\n","# axs[0, 0].plot(epochs, acc, 'r', label='Training Binary Accuracy')\r\n","# axs[0, 0].plot(epochs, val_acc, 'b', label='Validation Binary Accuracy')\r\n","# axs[0, 0].set_title('Training and Validation Binary Accuracy')\r\n","# axs[0, 0].legend()\r\n","\r\n","# axs[0, 1].plot(epochs, loss, 'r', label='Training Loss')\r\n","# axs[0, 1].plot(epochs, val_loss, 'b', label='Validation Loss')\r\n","# axs[0, 1].set_title('Training and Validation Loss')\r\n","# axs[0, 1].legend()\r\n","\r\n","# axs[1, 0].plot(epochs, auc, 'r', label='Training AUC')\r\n","# axs[1, 0].plot(epochs, val_auc, 'b', label='Validation AUC')\r\n","# axs[1, 0].set_title('Training and Validation AUROC')\r\n","# axs[1, 0].legend()\r\n","\r\n","# axs[1, 1].plot(epochs, fp, 'r', label='Training False Positives')\r\n","# axs[1, 1].plot(epochs, val_fp, 'b', label='Validation False Positives')\r\n","# axs[1, 1].set_title('Training and Validation False Positives')\r\n","# axs[1, 1].legend()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WwhdSvp_Oiw_"},"source":["# for DF_TYPE in tqdm(DF_TYPEZ):\r\n","#     for LOSS in tqdm(LOSSEZ):\r\n","#         for MDL in tqdm(PRE_TRAINED_MODELZ):\r\n","#             for OPTIMIZER in tqdm(OPTIMIZERZ):\r\n","                \r\n","#                 EXPERIMENT_NAME = f'{DF_TYPE}-{MDL}-{OPTIMIZER}'.replace('-', '_').lower()\r\n","\r\n","#                 try:\r\n","#                     os.mkdir(f'\\n./Checkpoints/{EXPERIMENT_NAME}')\r\n","#                 except OSError:\r\n","#                     try:\r\n","#                         print(f'loading model from ./Checkpoints/{EXPERIMENT_NAME}')\r\n","#                         tf.saved_model.load(f'./Checkpoints/{EXPERIMENT_NAME}')\r\n","#                     except: \r\n","#                         pass\r\n","\r\n","#                 TRAIN_VAL_DIR = f'./Celeb-DF-v2/Celeb-{DF_TYPE}'\r\n","#                 if 'bal' in TRAIN_VAL_DIR:\r\n","#                     TEST_DIR = TRAIN_VAL_DIR.replace('bal', 'test')\r\n","#                 else:\r\n","#                     TEST_DIR = f'{TRAIN_VAL_DIR}-test'\r\n","\r\n","#                 TRAIN_DATAGEN = ImageDataGenerator(rescale = 1./255.,\r\n","#                                                 rotation_range = 40,\r\n","#                                                 width_shift_range = 0.2,\r\n","#                                                 height_shift_range = 0.2,\r\n","#                                                 shear_range = 0.2,\r\n","#                                                 zoom_range = 0.2,\r\n","#                                                 horizontal_flip = True,\r\n","#                                                 validation_split = VALIDATION_SPLIT)\r\n","\r\n","#                 VAL_DATAGEN = ImageDataGenerator(rescale = 1.0/255., \r\n","#                                                 validation_split = VALIDATION_SPLIT)\r\n","\r\n","#                 TEST_DATAGEN = ImageDataGenerator(rescale = 1.0/255.)\r\n","\r\n","#                 TRAIN_GENERATOR = TRAIN_DATAGEN.flow_from_directory(directory = TRAIN_VAL_DIR,\r\n","#                                                                     batch_size = BACTH_SIZE,\r\n","#                                                                     class_mode = 'binary', \r\n","#                                                                     target_size = (IMG_HEIGHT, IMG_WIDTH),\r\n","#                                                                     subset = 'training',\r\n","#                                                                     seed = DATA_GENERATOR_SEED)\r\n","\r\n","#                 VALIDATION_GENERATOR = TRAIN_DATAGEN.flow_from_directory(directory = TRAIN_VAL_DIR,\r\n","#                                                                     batch_size = BACTH_SIZE,\r\n","#                                                                     class_mode = 'binary', \r\n","#                                                                     target_size = (IMG_HEIGHT, IMG_WIDTH),\r\n","#                                                                     subset = 'validation',\r\n","#                                                                     seed = DATA_GENERATOR_SEED)\r\n","\r\n","#                 TEST_GENERATOR = TEST_DATAGEN.flow_from_directory(directory = TEST_DIR,\r\n","#                                                                 batch_size = BACTH_SIZE,\r\n","#                                                                 class_mode = 'binary', \r\n","#                                                                 target_size = (IMG_HEIGHT, IMG_WIDTH),                                \r\n","#                                                                 seed = DATA_GENERATOR_SEED)\r\n","\r\n","#                 train_gen_list = list(TRAIN_GENERATOR.classes)\r\n","#                 val_gen_list = list(VALIDATION_GENERATOR.classes)\r\n","#                 test_gen_list = list(TEST_GENERATOR.classes)\r\n","\r\n","#                 train_neg, train_pos = train_gen_list.count(0), train_gen_list.count(1)\r\n","#                 val_neg, val_pos = val_gen_list.count(0), val_gen_list.count(1)\r\n","#                 test_neg, test_pos = test_gen_list.count(0), test_gen_list.count(1)\r\n","\r\n","#                 pos = train_pos + val_pos\r\n","#                 neg = train_neg + val_neg\r\n","#                 total = pos + neg\r\n","\r\n","#                 weight_for_0 = (1 / neg)*(total)/2.0 \r\n","#                 weight_for_1 = (1 / pos)*(total)/2.0\r\n","\r\n","#                 CLASS_WEIGHT = {0: weight_for_0, 1: weight_for_1}\r\n","\r\n","#                 STEP_SIZE_TRAIN = TRAIN_GENERATOR.n//TRAIN_GENERATOR.batch_size\r\n","#                 # STEP_SIZE_VALID = VALIDATION_GENERATOR.n//VALIDATION_GENERATOR.batch_size\r\n","\r\n","#                 EARLY_STOPPING = EarlyStopping(monitor = 'val_auc', \r\n","#                                             patience = EPOCHS//2,\r\n","#                                             mode = 'max',\r\n","#                                             verbose = 1,\r\n","#                                             restore_best_weights = True)\r\n","                \r\n","#                 REDUCE_LR  = ReduceLROnPlateau(monitor = 'val_auc', \r\n","#                                             patience = EPOCHS//6,\r\n","#                                             factor = 0.5,\r\n","#                                             verbose = 1,\r\n","#                                             min_lr=1e-6)\r\n","                \r\n","#                 MODEL_CHECKPOINT = ModelCheckpoint(filepath = f'./Checkpoints/{EXPERIMENT_NAME}/',\r\n","#                                                 monitor = 'val_auc',\r\n","#                                                 mode = 'max',\r\n","#                                                 verbose = 1,\r\n","#                                                 save_best_only = True)\r\n","                \r\n","#                 TENSOR_BOARD = TensorBoard(log_dir = f'./Checkpoints/{EXPERIMENT_NAME}/logs')\r\n","\r\n","#                 PRE_TRAINED_MODEL = eval(MDL)(input_shape = (IMG_HEIGHT,IMG_WIDTH,3),\r\n","#                                                             include_top = False,\r\n","#                                                             weights = 'imagenet')\r\n","\r\n","#                 for layer in PRE_TRAINED_MODEL.layers:\r\n","#                     layer.trainable = True\r\n","\r\n","#                 x = layers.Flatten()(PRE_TRAINED_MODEL.output)  \r\n","#                 x = layers.Dense(1024, activation = 'relu')(x)\r\n","#                 x = layers.Dropout(0.1)(x)\r\n","#                 # x = layers.Dense(512, activation = 'relu')(x)\r\n","#                 # x = layers.Dropout(0.2)(x)\r\n","#                 # x = layers.Dense(256, activation = 'relu')(x)\r\n","#                 # x = layers.Dropout(0.2)(x)\r\n","#                 # x = layers.Dense(128, activation = 'relu')(x)\r\n","#                 # x = layers.Dropout(0.2)(x)   \r\n","#                 # x = layers.Dense(64, activation = 'relu')(x)\r\n","#                 # x = layers.Dropout(0.2)(x)                    \r\n","#                 x = layers.Dense(1, activation = 'sigmoid')(x)  \r\n","\r\n","#                 MODEL = Model(PRE_TRAINED_MODEL.input, x) \r\n","\r\n","#                 MODEL.compile(optimizer = eval(OPTIMIZER)(learning_rate = LEARNING_RATE),\r\n","#                             loss = LOSS,\r\n","#                             metrics = [metrics.BinaryAccuracy(name = 'acc'),\r\n","#                                     metrics.AUC(name = 'auc'),\r\n","#                                     metrics.FalsePositives(name = 'fp')])\r\n","\r\n","#                 HISTORY = MODEL.fit(TRAIN_GENERATOR,\r\n","#                                     epochs = EPOCHS,\r\n","#                                     steps_per_epoch = STEP_SIZE_TRAIN,\r\n","#                                     validation_data = TEST_GENERATOR,\r\n","#                                     validation_steps = TEST_GENERATOR.n//TEST_GENERATOR.batch_size,\r\n","#                                     verbose = 1,\r\n","#                                     class_weight = CLASS_WEIGHT,\r\n","#                                     callbacks = [EARLY_STOPPING,\r\n","#                                                 REDUCE_LR,\r\n","#                                                 MODEL_CHECKPOINT,\r\n","#                                                 TENSOR_BOARD])\r\n","\r\n","#                 acc = HISTORY.history['acc']\r\n","#                 auc = HISTORY.history['auc']\r\n","#                 loss = HISTORY.history['loss']\r\n","#                 fp = HISTORY.history['fp']\r\n","\r\n","#                 val_acc = HISTORY.history['val_acc']\r\n","#                 val_auc = HISTORY.history['val_auc']\r\n","#                 val_loss = HISTORY.history['val_loss']\r\n","#                 val_fp = HISTORY.history['val_fp']\r\n","\r\n","#                 epochs = range(len(acc))\r\n","\r\n","#                 fig, axs = plt.subplots(2, 2, figsize = (20,20))\r\n","\r\n","#                 axs[0, 0].plot(epochs, acc, 'r', label='Training Binary Accuracy')\r\n","#                 axs[0, 0].plot(epochs, val_acc, 'b', label='Validation Binary Accuracy')\r\n","#                 axs[0, 0].set_title('Training and Validation Binary Accuracy')\r\n","#                 axs[0, 0].legend()\r\n","\r\n","#                 axs[0, 1].plot(epochs, loss, 'r', label='Training Loss')\r\n","#                 axs[0, 1].plot(epochs, val_loss, 'b', label='Validation Loss')\r\n","#                 axs[0, 1].set_title('Training and Validation Loss')\r\n","#                 axs[0, 1].legend()\r\n","\r\n","#                 axs[1, 0].plot(epochs, auc, 'r', label='Training AUC')\r\n","#                 axs[1, 0].plot(epochs, val_auc, 'b', label='Validation AUC')\r\n","#                 axs[1, 0].set_title('Training and Validation AUROC')\r\n","#                 axs[1, 0].legend()\r\n","\r\n","#                 axs[1, 1].plot(epochs, fp, 'r', label='Training False Positives')\r\n","#                 axs[1, 1].plot(epochs, val_fp, 'b', label='Validation False Positives')\r\n","#                 axs[1, 1].set_title('Training and Validation False Positives')\r\n","#                 axs[1, 1].legend()\r\n","\r\n","#                 fig.savefig(f'./Checkpoints/{EXPERIMENT_NAME}/{EXPERIMENT_NAME}_plt.png')\r\n","\r\n","#                 Y_pred = MODEL.predict(TEST_GENERATOR)\r\n","#                 Y_true = TEST_GENERATOR.classes\r\n","\r\n","#                 text_file = open(f'./Checkpoints/{EXPERIMENT_NAME}/{EXPERIMENT_NAME}_summary.txt', 'w')\r\n","\r\n","#                 text_file.write(f'\\n{EXPERIMENT_NAME}\\n')\r\n","#                 text_file.write(f'\\nTRAIN\\nReal samples = {train_neg}\\nFake samples = {train_pos}')\r\n","#                 text_file.write(f'\\nVALIDATION\\nReal samples = {val_neg}\\nFake samples = {val_pos}')\r\n","#                 text_file.write(f'\\nTEST\\nReal samples = {test_neg}\\nFake samples = {test_pos}')\r\n","#                 text_file.write(f'\\nWeight for Real = {weight_for_0:.5f}')\r\n","#                 text_file.write(f'\\nWeight for Fake = {weight_for_1:.5f}')\r\n","#                 # text_file.write(f'\\nTrain step size = {STEP_SIZE_TRAIN}')\r\n","#                 # text_file.write(f'\\nValidation step size = {STEP_SIZE_VALID}')\r\n","#                 text_file.write(f'\\nEarly Stop after {EARLY_STOPPING.patience} epochs of patience based on {EARLY_STOPPING.monitor}')\r\n","#                 text_file.write(f'\\nModel Checkpoints saved to {MODEL_CHECKPOINT.filepath} based on {MODEL_CHECKPOINT.monitor}')\r\n","#                 text_file.write(f'\\nLearning-Rate will reduce by a factor of {REDUCE_LR.factor} on {REDUCE_LR.monitor} plateu after {REDUCE_LR.patience} epochs of patience\\n')\r\n","#                 text_file.write(f'\\nTensor Board logs saved to {TENSOR_BOARD.log_dir}')\r\n","\r\n","#                 div = 100\r\n","#                 for thrshld in map(lambda x: x/div, range(0,div+1)):\r\n","#                     y_pred = (Y_pred > thrshld).astype(int)\r\n","#                     text_file.write(f'\\nTHRESHOLD = {thrshld}')\r\n","#                     text_file.write(f'\\nCONFUSION MATRIX\\n{confusion_matrix(Y_true, y_pred)}')\r\n","#                     text_file.write(f'\\nCLASSIFICATION REPORT\\n{classification_report(Y_true, y_pred, target_names = [\"REAL\", \"FAKE\"])}\\n\\n')\r\n","#                     text_file.write('________________________________________________________________\\n\\n')\r\n","                    \r\n","#                 text_file.write(str(HISTORY.history).replace(', \\'', ':\\n\\n'))\r\n","#                 text_file.close()"],"execution_count":null,"outputs":[]}]}